{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed6af078-63e3-40bd-b71c-461ccbaabb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1180b2c6-c6d5-441b-a419-80bac627ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the path to the dataset directory\n",
    "images_dir = '/Users/manish/Downloads/PokemonData'  # Replace this with the actual path to your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54445e60-2bca-4d0a-b554-10f246410607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory confirmed: /Users/manish/Downloads/PokemonData\n"
     ]
    }
   ],
   "source": [
    "# Verify if the dataset exists\n",
    "if not os.path.exists(images_dir):\n",
    "    raise FileNotFoundError(f\"Dataset directory not found at: {images_dir}\")\n",
    "print(f\"Dataset directory confirmed: {images_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe26749f-fc37-47ad-927b-e321261e296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Verify and clean the dataset\n",
    "def check_images(directory):\n",
    "    \"\"\"\n",
    "    Verifies the integrity of images in the directory and removes corrupted ones.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            img_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()  # Verifies the image integrity\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Corrupted image found: {img_path}\")\n",
    "                os.remove(img_path)  # Optionally delete the corrupted image\n",
    "\n",
    "def convert_images_to_rgb(directory):\n",
    "    \"\"\"\n",
    "    Converts all images to RGB format (if not already in RGB format).\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            img_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    if img.mode != 'RGB':  # Convert non-RGB images to RGB\n",
    "                        img = img.convert('RGB')\n",
    "                    img.save(img_path)  # Overwrite the image in the same directory\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "034d7111-a35f-408b-b53b-2a1801264a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images...\n",
      "Skipping invalid file: /Users/manish/Downloads/PokemonData/Venusaur/e20dd0c9dbae4a299b32be5f486e4143.jpg\n",
      "Skipping invalid file: /Users/manish/Downloads/PokemonData/Onix/Onix58.jpg\n",
      "Skipping invalid file: /Users/manish/Downloads/PokemonData/Onix/a445ddff0c6640a381e2da954f117e88.jpg\n",
      "Skipping invalid file: /Users/manish/Downloads/PokemonData/Onix/Onix46.jpg\n",
      "Skipping invalid file: /Users/manish/Downloads/PokemonData/Seadra/a9e0e66523a5477fb8cb58b57d89af24.jpg\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_images(directory):\n",
    "    \"\"\"\n",
    "    Ensures all images in the directory are in RGB format.\n",
    "    Converts palette-based images with transparency to RGBA, and saves them as PNG.\n",
    "    JPEG images are saved without any transparency.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            img_path = os.path.join(root, file)\n",
    "\n",
    "            # Check if the file is a valid image\n",
    "            if imghdr.what(img_path) is None:\n",
    "                print(f\"Skipping invalid file: {img_path}\")\n",
    "                continue  # Skip invalid files\n",
    "\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    # If the image is PNG and has transparency, save it as PNG\n",
    "                    if img.mode in (\"P\", \"L\", \"LA\"):\n",
    "                        img = img.convert(\"RGBA\")\n",
    "                        if img.format == \"PNG\":  # Save as PNG to preserve transparency\n",
    "                            img.save(img_path)\n",
    "                        else:  # If it's not a PNG, save it in a format that doesn't support transparency (e.g., JPEG)\n",
    "                            img = img.convert(\"RGB\")  # Remove alpha channel and save as RGB\n",
    "                            img.save(img_path, format=\"JPEG\")\n",
    "                    else:\n",
    "                        # For images that don't have transparency (e.g., JPG), save as RGB\n",
    "                        if img.mode != \"RGB\":\n",
    "                            img = img.convert(\"RGB\")\n",
    "                        img.save(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Preprocessing images...\")\n",
    "preprocess_images(images_dir)\n",
    "print(\"Preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de67202f-bfd7-4bb0-8be4-f187a144c192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16137 images belonging to 151 classes.\n",
      "Found 3962 images belonging to 151 classes.\n",
      "Training data: 16137 images across 151 classes.\n",
      "Validation data: 3962 images across 151 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values\n",
    "    validation_split=0.2  # Split for training and validation\n",
    ")\n",
    "\n",
    "# Prepare training and validation data generators\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    images_dir,  # Base directory\n",
    "    target_size=(224, 224),  # Resize images for the model\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    images_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Log dataset stats\n",
    "print(f\"Training data: {train_gen.samples} images across {len(train_gen.class_indices)} classes.\")\n",
    "print(f\"Validation data: {val_gen.samples} images across {len(val_gen.class_indices)} classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "547c3485-1a4f-490e-a7fa-01355bfc255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_gen.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "608a95b8-d0b5-4dcf-af5b-7f14ff6c7c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/505\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 586ms/step - accuracy: 0.0082 - loss: 5.0799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 02:16:03.002426: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x15d3bf970>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n",
      "    for i, batch in enumerate(gen_fn()):\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n",
      "    yield self.py_dataset[i]\n",
      "          ~~~~~~~~~~~~~~~^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/PIL/Image.py\", line 3498, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x15d3bf970>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m145/505\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 586ms/step - accuracy: 0.0082 - loss: 5.0795"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x15d3bf970>\nTraceback (most recent call last):\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n          ~~~~~~~~~~~~~~~^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/PIL/Image.py\", line 3498, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x15d3bf970>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_7377]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting model training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Save training results\u001b[39;00m\n\u001b[1;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_history\u001b[39m\u001b[38;5;124m'\u001b[39m: history\u001b[38;5;241m.\u001b[39mhistory}\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x15d3bf970>\nTraceback (most recent call last):\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n          ~~~~~~~~~~~~~~~^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/manish/tensorflow_env/lib/python3.12/site-packages/PIL/Image.py\", line 3498, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x15d3bf970>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_7377]"
     ]
    }
   ],
   "source": [
    "# Define callbacks with path in the writable directory\n",
    "model_filename = \"best_model_pokemon_custom_cnn.keras\"  # Save the model to the current directory or specify another path\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(model_filename, save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save training results\n",
    "results = {'model_history': history.history}\n",
    "results_path = \"model_results.json\"  # Save results to the current directory or specify another path\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Save model in .h5 format in the current directory or specify another path\n",
    "model_h5_path = \"pokemon_model.h5\"\n",
    "model.save(model_h5_path)\n",
    "\n",
    "# Print the paths where results are saved\n",
    "print(f\"Training complete. Results saved to '{results_path}'. Model saved to '{model_filename}' and '{model_h5_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c103f8-ee1f-488b-86d4-151d86141ada",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Displaying training and validation accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Displaying training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
