{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c21ac8-41a4-4abd-852f-d0ff54cf48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/4zvprj0557j9svvr35zx8q800000gn/T/ipykernel_984/2769102282.py:3: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbackas import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f161de-e96a-4792-b8f2-f10fe5301b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory confirmed: /Users/manish/Downloads/PokemonData\n"
     ]
    }
   ],
   "source": [
    "# Manually set the path to the dataset directory\n",
    "images_dir = '/Users/manish/Downloads/PokemonData'  \n",
    "\n",
    "# Verify if the dataset exists\n",
    "if not os.path.exists(images_dir):\n",
    "    raise FileNotFoundError(f\"Dataset directory not found at: {images_dir}\")\n",
    "print(f\"Dataset directory confirmed: {images_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0c48fb-9f35-43de-a0a0-e565d03cf896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking and cleaning the dataset...\n",
      "Corrupted or invalid image found: /Users/manish/Downloads/PokemonData/.DS_Store\n",
      "Preprocessing images...\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# Verify and clean the dataset\n",
    "def check_images(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            img_path = os.path.join(root, file)\n",
    "            if not is_valid_image(img_path):\n",
    "                print(f\"Corrupted or invalid image found: {img_path}\")\n",
    "                os.remove(img_path)  # Optionally delete the corrupted image\n",
    "\n",
    "def is_valid_image(img_path):\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img.verify()  # Verifies the image integrity\n",
    "        return True\n",
    "    except (IOError, SyntaxError, UnidentifiedImageError):\n",
    "        return False\n",
    "\n",
    "def preprocess_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            img_path = os.path.join(root, file)\n",
    "\n",
    "            # Check if the file is a valid image\n",
    "            if imghdr.what(img_path) is None or not is_valid_image(img_path):\n",
    "                print(f\"Skipping invalid or corrupted file: {img_path}\")\n",
    "                continue  # Skip invalid files\n",
    "\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    # If the image is PNG and has transparency, save it as PNG\n",
    "                    if img.mode in (\"P\", \"L\", \"LA\"):\n",
    "                        img = img.convert(\"RGBA\")\n",
    "                        if img.format == \"PNG\":  # Save as PNG to preserve transparency\n",
    "                            img.save(img_path)\n",
    "                        else:  # If it's not a PNG, save it in a format that doesn't support transparency (e.g., JPEG)\n",
    "                            img = img.convert(\"RGB\")  # Remove alpha channel and save as RGB\n",
    "                            img.save(img_path, format=\"JPEG\")\n",
    "                    else:\n",
    "                        # For images that don't have transparency (e.g., JPG), save as RGB\n",
    "                        if img.mode != \"RGB\":\n",
    "                            img = img.convert(\"RGB\")\n",
    "                        img.save(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "# Apply preprocessing and clean the dataset\n",
    "print(\"Checking and cleaning the dataset...\")\n",
    "check_images(images_dir)\n",
    "print(\"Preprocessing images...\")\n",
    "preprocess_images(images_dir)\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fed7809-21c3-45c1-b137-cc030fd649e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16133 images belonging to 151 classes.\n",
      "Found 3961 images belonging to 151 classes.\n",
      "Training data: 16133 images across 151 classes.\n",
      "Validation data: 3961 images across 151 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values\n",
    "    validation_split=0.2  # Split for training and validation\n",
    ")\n",
    "\n",
    "# Prepare training and validation data generators\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    images_dir,  # Base directory\n",
    "    target_size=(224, 224),  # Resize images for the model\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    images_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Log dataset stats\n",
    "print(f\"Training data: {train_gen.samples} images across {len(train_gen.class_indices)} classes.\")\n",
    "print(f\"Validation data: {val_gen.samples} images across {len(val_gen.class_indices)} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd26feb-0854-4d7c-8f4d-c976e2540d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manish/tensorflow_env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - accuracy: 0.0174 - loss: 4.9432\n",
      "Epoch 1: val_loss improved from inf to 3.81833, saving model to best_model_pokemon_custom_cnn.keras\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 655ms/step - accuracy: 0.0175 - loss: 4.9427 - val_accuracy: 0.1444 - val_loss: 3.8183\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.0984 - loss: 3.9808\n",
      "Epoch 2: val_loss improved from 3.81833 to 2.75882, saving model to best_model_pokemon_custom_cnn.keras\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 723ms/step - accuracy: 0.0984 - loss: 3.9804 - val_accuracy: 0.3552 - val_loss: 2.7588\n",
      "Epoch 3/10\n",
      "\u001b[1m 81/505\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:55\u001b[0m 979ms/step - accuracy: 0.1891 - loss: 3.2648"
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_gen.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks with path in the writable directory\n",
    "model_filename = \"best_model_pokemon_custom_cnn.keras\"  \n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(model_filename, save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save training results\n",
    "results = {'model_history': history.history}\n",
    "results_path = \"model_results.json\"  \n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Save model in .h5 format in the current directory \n",
    "model_h5_path = \"pokemon_model.h5\"\n",
    "model.save(model_h5_path)\n",
    "\n",
    "# Print the paths where results are saved\n",
    "print(f\"Training complete. Results saved to '{results_path}'. Model saved to '{model_filename}' and '{model_h5_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18d80c-6ae6-4e9c-8ffa-8c5a2c0bb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70619eb1-27f0-456a-a655-82c851e09be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
